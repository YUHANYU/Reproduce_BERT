阅读论文 *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*，复现**BERT**模型。

代码还在调试编码阶段，尚未完成。
